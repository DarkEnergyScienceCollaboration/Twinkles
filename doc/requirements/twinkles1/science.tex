% ====================================================================
\section{Science Analysis}
\label{sec:twinkles1:science}
% ====================================================================

\contact{Phil Marshall}{@drphilmarshall},
\contact{Michael Wood-Vasey}{@wmwv},

Below we describe the supernova and strong lensing science analysis
that we want to do with the \TwinklesOne data, and that can be done
in the 2016--2017 time frame using available simulation and analysis
technology and computing infrastructure. In each case we first
introducing the measurement issues we face, and then define the
investigations of them that we want to do. These then dictate the
requirements we have on the challenge dataset design.

A note on terminology: we refer to the process of light curve
extraction as ``Monitoring.'' Supernova light curve extraction will be
performed by a  tool referred to as \SNMonitor, and strong lens light
curve extraction  by a related piece of software called \SLMonitor.
For strong lenses, the key parameter to be inferred  from a set of
light curves is the time delay, and so we refer to the software tool
that  performs that inference as \SLTimer. Supernova light curve
parameters  are typically inferred with tools known as
``light curve fitters,'' to be deployed by the code \SNDistance.


% --------------------------------------------------------------------

\subsection{Supernovae}
\label{sec:twinkles1:science:supernovae}

Introduction to supernova analysis in \TwinklesOne.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

\subsubsection{Proposed Analyses}
\label{sec:twinkles1:science:supernovae:analyses}

We propose to answer the following questions:

% Light curves
\begin{itemize}
\item Is the photometric calibration accurate?
\end{itemize}

For this we will need the \TwinklesOne survey to have the following
properties:
\begin{itemize}
\item The field should contain at least 100 active SNeIa with the expectation of at least 5 observations at SNR$>5$ during the simulated time period, and 100 active SNeIa that we expect to fall below a SNR$>5$ threshold.  This should be a loosely continuous distribution of apparent brightness.
\item SN should be placed on galaxies or galaxy locations with different surface brightness.
\end{itemize}

Object detection and light-curve extraction:
\begin{itemize}
\item Does the fraction of SN recovered match the Poisson prediction?
\item Is forced photometry for variable sources in difference images correct in its precision?
\item Is forced photometry for variable sources in difference images accurate in its calibration?
\item Do the recovered lightcurves of supernova match the input simulation specification to the expected precision?
\item Does the supernova detection efficiency on host-galaxy light contamination follow the Poisson noise?
\end{itemize}



% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -


% --------------------------------------------------------------------

\subsection{Strong Lensing}
\label{sec:twinkles1:science:stronglensing}

From the first Time Delay Challenge we know that around 400 lensed
quasars (defined here as the ``Gold Sample'') should be measurable
with cosmological accuracy with LSST, provided that a) 6 day cadence
can be achieved and b) the light curves extracted from the LSST images
are as clean as those in the challenge.

6-day cadence requires 5 filters to be used: TDC2 will test
assumption a) above, that  a 5--6 filter light curve can be modeled as
accurately as a single filter light curve. The fidelity of the light
curves depends on our ability to extract them, and this requires image
simulations of very high realism to be analyzed with the tools of
sufficient sharpness.

In \TwinklesOne we will test assumption b), and assess the fidelity of
lensed quasar light curves as observed and measured with the LSST system.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

\subsubsection{Light Curve Extraction Issues}
\label{sec:twinkles1:science:stronglensing:monitor}

Point image separation (deblending).

Photometric accuracy (forced photometry).

Lens and host galaxy light contamination.


% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

\subsubsection{Time Delay Measurement Issues}
\label{sec:twinkles1:science:stronglensing:timedelay}

Correlated photometric error accuracy and mitigation.


% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

\subsubsection{Proposed Analyses}
\label{sec:twinkles1:science:stronglensing:analyses}

We propose to answer the following questions:
\begin{itemize}
\item Was the quality of the TDC1 Gold Sample photometry realistic?
\item How can we better model LSST lensed quasar photometry in future time delay challenges?
\end{itemize}

For this we will need the \TwinklesOne survey to have the following
properties:
\begin{itemize}
\item The field should contain a significant random fraction (at least
25\%,  and preferably 100\%) of the TDC1 Gold Sample of 400 lensed
quasars,  which should vary in the same way as the TDC1 objects (at
least with regard to their  AGN variability, which dominates over
microlensing).
\item The survey should simulate 10 years of LSST observing in
wide-fast-deep (WFD) strategy, with realistic observing conditions.
\item Images should be in either $r$ or $i$-band, as assumed in TDC1.
\item The survey can be single filter, but the mean night-to-night
cadence needs to be 6 days, to allow comparison with TDC1.
\end{itemize}

After light curve extraction we will then perform the following tests:
\begin{itemize}
\item The noise properties of the \TwinklesOne and TDC1 light curves
will be summarized and compared.
\item Time delays will be measured for each system using the fiducial
TDC1 algorithm, and the mean accuracy compared against that in TDC1.
\end{itemize}


% ====================================================================
